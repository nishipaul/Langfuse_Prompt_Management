{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23506068-eed4-4dee-93d3-4d74004d4932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loading the environment keys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4161ac-2596-41f4-9762-b0db79d7cc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://langfuse.simpplr.xyz'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGFUSE_HOST\") # Confirming use of simpplr host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7496cf01-91bd-4e99-96f0-5fa89c81e9cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Creating the client that will connect with the project via keys and host\n",
    "langfuse_client = Langfuse(\n",
    "    secret_key = os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    public_key = os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    host = os.getenv(\"LANGFUSE_HOST\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf263317-3ae5-4309-8a78-e5f7ff2272b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.model.TextPromptClient at 0x1289c3e00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Procedure to create a prompt and load it in the project\n",
    "\n",
    "langfuse_client.create_prompt(\n",
    "    name = \"teacher-assistant\",\n",
    "    type = \"text\",\n",
    "    prompt = \"As a {{criticlevel}} teaching expert, are you satisfied with the answer of {{answer}}? Tell in short\",\n",
    "    config = {\n",
    "        \"model\" : \"llama3:8b\", \"temperature\":0.3, \"top_p\":0.1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7192ec14-8db5-49cb-bf5d-4659e1a9d5d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the created prompt from the project\n",
    "\n",
    "langfuse_prompt = langfuse_client.get_prompt(\"teacher-assistant\", version=1)\n",
    "\n",
    "# Converting it into langchain type\n",
    "langchain_prompt = ChatPromptTemplate.from_template(langfuse_prompt.get_langchain_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9878f7c-e13a-4448-aed6-f491f9ea9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langfuse.langchain import CallbackHandler # for tracing\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "#langfuse_callback_handler = CallbackHandler() # Used for tracing purpose\n",
    "\n",
    "# Picking up the model configurations from the prompt stored in langfuse. This is optional.\n",
    "model = langfuse_prompt.config[\"model\"]\n",
    "temperature = str(langfuse_prompt.config[\"temperature\"])\n",
    "top_p = str(langfuse_prompt.config[\"top_p\"])\n",
    "\n",
    "# Using the ChatOllama model for output generation\n",
    "llm = ChatOllama(model = model, temperature=temperature, top_p = top_p)\n",
    "\n",
    "# Chaining prompt with model\n",
    "llm_chain = langchain_prompt | llm\n",
    "\n",
    "# creating user input\n",
    "user_input = {\n",
    "    \"criticlevel\" : \"starting\",\n",
    "    \"answer\" : \"The Earth is flat\"\n",
    "}\n",
    "\n",
    "# Calling the model with user input for generation\n",
    "response = llm_chain.invoke(input = user_input,\n",
    "                           #config = {\n",
    "                           #    \"callbacks\":[langfuse_callback_handler]} # Uncomment for tracing\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af12145d-f402-4580-8d58-6ee0fd645d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No! As a starting teaching expert, I can confidently say that the answer \"The Earth is flat\" is not accurate and lacks scientific evidence. In fact, overwhelming scientific consensus confirms that the Earth is an oblate spheroid (a slightly flattened sphere). The evidence from various fields such as astronomy, geology, physics, and more all support a round Earth.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19124b1a-26ea-4d47-9b79-b2393a97c489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5dc691-5b0f-4776-be98-6942620d3760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
