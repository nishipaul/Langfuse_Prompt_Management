{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf00043-c8fa-4576-9188-2f3f91f11e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loading the environment keys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d439ca-ce51-4158-816f-47dcf1f7c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Creating the client that will connect with the project via keys and host\n",
    "langfuse_client = Langfuse(\n",
    "    secret_key = os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    public_key = os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    host = os.getenv(\"LANGFUSE_HOST\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b8981c-45eb-40ca-97b0-a8034ea398f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.model.ChatPromptClient at 0x1084de900>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse_client.create_prompt(\n",
    "    name = \"HR-Assistant\",\n",
    "    type = \"chat\",\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\" : \"system\",\n",
    "            \"content\" : \"You are {{experiencelevel}} HR\"\n",
    "        },\n",
    "        {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : \"What should I do to take leave?\"\n",
    "        }\n",
    "    ],\n",
    "    labels = [\"production\", \"hr\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba64f51-3ee8-419b-91c6-011fb1e40e5b",
   "metadata": {},
   "source": [
    "### Using Langchain to resolve the placeholders at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aee20176-9872-4a45-ad01-1ef4a806942c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['answer', 'criticlevel'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['answer', 'criticlevel'], input_types={}, partial_variables={}, template='As a {criticlevel} teaching expert, are you satisfied with the answer of {answer}? Explain in detail'), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Use this for type=\"text\" prompt\n",
    "langfuse_prompt = langfuse_client.get_prompt(\"teacher-assistant\", label=\"testing\")\n",
    "langchain_prompt = ChatPromptTemplate.from_template(langfuse_prompt.get_langchain_prompt())\n",
    "langchain_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf26a1c-9fd7-49d9-b919-ec4ff2d4bcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['experiencelevel'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['experiencelevel'], input_types={}, partial_variables={}, template='You are {experiencelevel} HR'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='What should I do to take leave?'), additional_kwargs={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this for type=\"chat\" prompt\n",
    "langfuse_prompt = langfuse_client.get_prompt(\"HR-Assistant\")\n",
    "prompt_messages = langfuse_prompt.get_langchain_prompt()\n",
    "langchain_prompt = ChatPromptTemplate.from_messages(prompt_messages)\n",
    "langchain_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f916a3d9-ab39-49de-92ff-f3a426fc47dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = \"llama3:8b\"\n",
    "temperature = 0.4\n",
    "top_p = 0.1\n",
    "\n",
    "llm = ChatOllama(model = model, temperature=temperature, top_p = top_p)\n",
    "\n",
    "llm_chain = langchain_prompt | llm\n",
    "\n",
    "user_input = {\n",
    "    \"experiencelevel\" : \"senior\"\n",
    "}\n",
    "\n",
    "response = llm_chain.invoke(input = user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "413d0723-1571-40bb-b2b1-2cf87d5425b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a senior HR representative, I'd be happy to guide you through the process of taking leave.\n",
      "\n",
      "To request leave, please follow these steps:\n",
      "\n",
      "1. Check your company's leave policy: Review our company's leave policy to ensure you understand the types of leave available (e.g., vacation, sick, family and medical, etc.) and the procedures for requesting time off.\n",
      "2. Determine the type of leave you need: Decide which type of leave you require (vacation, sick, or family and medical) and how many days you need to take off.\n",
      "3. Submit your request: Fill out the Leave Request Form (available on our HR portal or by contacting me directly) with the following information:\n",
      "\t* Your name\n",
      "\t* The dates you wish to take leave\n",
      "\t* The type of leave requested\n",
      "\t* A brief explanation for the reason, if applicable (for family and medical leave only)\n",
      "4. Submit your request in a timely manner: Try to submit your request at least 2 weeks prior to the start date of your leave, but no later than 1 week before.\n",
      "5. Wait for approval: I'll review your request and notify you within 3 business days if it's approved or if additional information is needed.\n",
      "\n",
      "Some important notes:\n",
      "\n",
      "* If you're requesting vacation time, please ensure that your manager has been notified and has approved the dates.\n",
      "* For family and medical leave, you may need to provide documentation from a healthcare provider or other relevant evidence.\n",
      "* In cases of unexpected absences (e.g., illness), please notify me as soon as possible.\n",
      "\n",
      "Remember, it's essential to follow our company's leave policy and procedures to ensure a smooth process for both you and the organization. If you have any questions or concerns, don't hesitate to reach out to me directly.\n",
      "\n",
      "Now, go ahead and submit your leave request!\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf15b76-5965-4bc6-b793-e8e555500da2",
   "metadata": {},
   "source": [
    "### Using Python to resolve the placeholders at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "169e8a78-b9ff-4259-8e44-3af736e54ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse_prompt.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58b8e922-7f5b-4fbb-9c18-b4f89d61ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse_prompt = langfuse_client.get_prompt(\"HR-Assistant\")\n",
    "\n",
    "compiled_prompt = langfuse_prompt.compile(experiencelevel = \"fresher\",\n",
    "                                         chat_history = [\n",
    "                                             {\"role\" : \"user\", \"content\" : \"I am going to take a leave tomorrow\"},\n",
    "                                             {\"role\" : \"user\", \"content\" : \"I want to encash my leaves\"}\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24ed1305-b62f-4fde-98c0-ca0d15c4a1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are fresher HR'},\n",
       " {'role': 'user', 'content': 'What should I do to take leave?'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e5fc00c-1d13-4213-a1bb-8a78d89c6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ca3d389-bcdb-4b20-8953-10018dc757fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3:8b\"\n",
    "temperature = 0.4\n",
    "top_p = 0.1\n",
    "\n",
    "response = ollama.chat(\n",
    "    model = model,\n",
    "    options={\n",
    "        \"temperature\": temperature,  \n",
    "        \"top_p\": top_p        \n",
    "    },\n",
    "    messages=compiled_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "939ba1c3-9bea-410f-a8a9-d918112a17f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To take a leave, you can follow these steps:\n",
      "\n",
      "1. Check the company's leave policy: Before taking a leave, please review our company's leave policy to ensure you understand the rules and procedures.\n",
      "2. Submit your request: You can submit your leave request through our HR system or by sending an email to me (your HR representative).\n",
      "3. Provide necessary details: When submitting your request, please provide the following information:\n",
      "\t* Date(s) of leave\n",
      "\t* Reason for leave (optional)\n",
      "\t* Number of days off requested\n",
      "4. Get approval: Once you've submitted your request, I'll review it and get back to you with an approval or rejection.\n",
      "5. Confirm with your manager: If approved, please confirm the leave with your manager to ensure they're aware of your absence.\n",
      "\n",
      "Some important notes:\n",
      "\n",
      "* Leave requests should be made at least 2 days in advance (whenever possible).\n",
      "* You can only take a maximum of [insert number] days off per year.\n",
      "* If you need to take an extended leave, please discuss this with me and your manager before making the request.\n",
      "\n",
      "Remember to keep records of your leave taken and ensure you're not exceeding the allowed number of days. If you have any questions or concerns, feel free to reach out to me!\n"
     ]
    }
   ],
   "source": [
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6725c7-2dac-42c8-b7ee-080651a801b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
